{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 10:27:12.623190: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-05 10:27:12.632421: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-05 10:27:12.644263: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-05 10:27:12.644293: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-05 10:27:12.654201: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-05 10:27:13.160229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import ImageTool.tool as tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from efficientunet2 import get_efficientunet_b2\n",
    "from models.Basic_module import Criterion\n",
    "# from Basic_module import Criterion, Visualization\n",
    "from ResNet3D import ResNet_appearance, ResNet_shape\n",
    "\n",
    "\n",
    "class BayeSeg(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(BayeSeg, self).__init__()\n",
    "\n",
    "        self.args = args\n",
    "        self.num_classes = args.num_classes\n",
    "\n",
    "        self.res_shape = ResNet_shape(num_out_ch=2)\n",
    "        self.res_appear = ResNet_appearance(num_out_ch=2, num_block=6, bn=True)\n",
    "        self.unet = get_efficientunet_b2(      \n",
    "            out_channels=2 * args.num_classes, pretrained=False\n",
    "        )\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        Dx = torch.zeros([1, 1, 3, 3, 3], dtype=torch.float)\n",
    "        Dx[0, 0, 1, 1, 1] = 1\n",
    "\n",
    "        # 6-neighborhood in 3D (±x, ±y, ±z), each -1/6 for a simple Laplacian\n",
    "        Dx[0, 0, 1, 1, 0] = -1/6  # left\n",
    "        Dx[0, 0, 1, 1, 2] = -1/6  # right\n",
    "        Dx[0, 0, 1, 0, 1] = -1/6  # up\n",
    "        Dx[0, 0, 1, 2, 1] = -1/6  # down\n",
    "        Dx[0, 0, 0, 1, 1] = -1/6  # front\n",
    "        Dx[0, 0, 2, 1, 1] = -1/6\n",
    "        # Dx[:, :, 1, 1] = 1\n",
    "        # Dx[:, :, 1, 0] = Dx[:, :, 1, 2] = Dx[:, :, 0, 1] = Dx[:, :, 2, 1] = -1 / 4\n",
    "        self.Dx = nn.Parameter(data=Dx, requires_grad=False)\n",
    "\n",
    "    @staticmethod\n",
    "    def sample_normal_jit(mu, log_var):\n",
    "        sigma = torch.exp(log_var / 2)\n",
    "        eps = mu.mul(0).normal_()\n",
    "        z = eps.mul_(sigma).add_(mu)\n",
    "        return z, eps\n",
    "\n",
    "    def generate_m(self, samples):\n",
    "        feature = self.res_appear(samples)\n",
    "        mu_m, log_var_m = torch.chunk(feature, 2, dim=1)\n",
    "        log_var_m = torch.clamp(log_var_m, -20, 0)\n",
    "        m, _ = self.sample_normal_jit(mu_m, log_var_m)\n",
    "        return m, mu_m, log_var_m\n",
    "\n",
    "    def generate_x(self, samples):\n",
    "        feature = self.res_shape(samples)\n",
    "        mu_x, log_var_x = torch.chunk(feature, 2, dim=1)\n",
    "        log_var_x = torch.clamp(log_var_x, -20, 0)\n",
    "        x, _ = self.sample_normal_jit(mu_x, log_var_x)\n",
    "        return x, mu_x, log_var_x\n",
    "\n",
    "    def generate_z(self, x):\n",
    "        feature = self.unet(x.repeat(1, 3, 1, 1, 1))\n",
    "        mu_z, log_var_z = torch.chunk(feature, 2, dim=1)\n",
    "        log_var_z = torch.clamp(log_var_z, -20, 0)\n",
    "        z, _ = self.sample_normal_jit(mu_z, log_var_z)\n",
    "        if self.training:\n",
    "            return F.gumbel_softmax(z, dim=1), F.gumbel_softmax(mu_z, dim=1), log_var_z\n",
    "        else:\n",
    "            return self.softmax(z), self.softmax(mu_z), log_var_z\n",
    "\n",
    "    def forward(self, samples: torch.Tensor):\n",
    "        x, mu_x, log_var_x = self.generate_x(samples)\n",
    "        m, mu_m, log_var_m = self.generate_m(samples)\n",
    "        z, mu_z, log_var_z = self.generate_z(x)\n",
    "        K = self.num_classes\n",
    "        _, _, W, H, D = samples.shape\n",
    "\n",
    "        residual = samples - (x + m)\n",
    "        mu_rho_hat = (2 * self.args.gamma_rho + 1) / (\n",
    "            residual * residual + 2 * self.args.phi_rho\n",
    "        )\n",
    "        mu_rho_hat = torch.clamp(mu_rho_hat, 1e4, 1e8)\n",
    "\n",
    "        normalization = torch.sum(mu_rho_hat).detach()\n",
    "        n, _ = self.sample_normal_jit(m, torch.log(1 / mu_rho_hat))\n",
    "\n",
    "        # # Image line upsilon\n",
    "        alpha_upsilon_hat = 2 * self.args.gamma_upsilon + K\n",
    "        difference_x = F.conv3d(mu_x, self.Dx, padding=1)\n",
    "\n",
    "        beta_upsilon_hat = (\n",
    "            torch.sum(\n",
    "                mu_z * (difference_x * difference_x + 2 * torch.exp(log_var_x)),\n",
    "                dim=1,\n",
    "                keepdim=True,\n",
    "            )\n",
    "            + 2 * self.args.phi_upsilon\n",
    "        )  # B x 1 x W x H\n",
    "\n",
    "        mu_upsilon_hat = alpha_upsilon_hat / beta_upsilon_hat\n",
    "        # mu_upsilon_hat = torch.clamp(mu_upsilon_hat, 1e6, 1e10)\n",
    "\n",
    "        # # Seg boundary omega\n",
    "        difference_z = F.conv3d(\n",
    "            mu_z, self.Dx.expand(K, 1, 3, 3, 3), padding=1, groups=K\n",
    "        )  # B x K x W x H\n",
    "        alpha_omega_hat = 2 * self.args.gamma_omega + 1\n",
    "        pseudo_pi = torch.mean(mu_z, dim=(2, 3,4), keepdim=True)\n",
    "        beta_omega_hat = (\n",
    "            pseudo_pi * (difference_z * difference_z + 2 * torch.exp(log_var_z))\n",
    "            + 2 * self.args.phi_omega\n",
    "        )\n",
    "        mu_omega_hat = alpha_omega_hat / beta_omega_hat\n",
    "        mu_omega_hat = torch.clamp(mu_omega_hat, 1e2, 1e6)\n",
    "\n",
    "        # # Seg category probability pi\n",
    "        _, _, W, H, D = samples.shape\n",
    "        alpha_pi_hat = self.args.alpha_pi + W * H * D / 2\n",
    "        beta_pi_hat = (\n",
    "            torch.sum(\n",
    "                mu_omega_hat * (difference_z * difference_z + 2 * torch.exp(log_var_z)),\n",
    "                dim=(2, 3, 4),\n",
    "                keepdim=True,\n",
    "            )\n",
    "            / 2\n",
    "            + self.args.beta_pi\n",
    "        )\n",
    "        digamma_pi = torch.special.digamma(\n",
    "            alpha_pi_hat + beta_pi_hat\n",
    "        ) - torch.special.digamma(beta_pi_hat)\n",
    "        # # compute loss-related\n",
    "        kl_y = residual * mu_rho_hat.detach() * residual\n",
    "\n",
    "        kl_mu_z = torch.sum(\n",
    "            digamma_pi.detach() * difference_z * mu_omega_hat.detach() * difference_z,\n",
    "            dim=1,\n",
    "        )\n",
    "        kl_sigma_z = torch.sum(\n",
    "            digamma_pi.detach()\n",
    "            * (2 * torch.exp(log_var_z) * mu_omega_hat.detach() - log_var_z),\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        kl_mu_x = torch.sum(\n",
    "            difference_x * difference_x * mu_upsilon_hat.detach() * mu_z.detach(), dim=1\n",
    "        )\n",
    "        kl_sigma_x = (\n",
    "            torch.sum(\n",
    "                2 * torch.exp(log_var_x) * mu_upsilon_hat.detach() * mu_z.detach(),\n",
    "                dim=1,\n",
    "            )\n",
    "            - log_var_x\n",
    "        )\n",
    "\n",
    "        kl_mu_m = self.args.sigma_0 * mu_m * mu_m\n",
    "        kl_sigma_m = self.args.sigma_0 * torch.exp(log_var_m) - log_var_m\n",
    "\n",
    "        visualize = {\n",
    "            \"shape\": torch.concat([x, mu_x, torch.exp(log_var_x / 2)]),\n",
    "            \"appearance\": torch.concat([n, m, 1 / mu_rho_hat.sqrt()]),\n",
    "            \"logit\": torch.concat(\n",
    "                [\n",
    "                    z[:, 1:2, ...],\n",
    "                    mu_z[:, 1:2, ...],\n",
    "                    torch.exp(log_var_z / 2)[:, 1:2, ...],\n",
    "                ]\n",
    "            ),\n",
    "            \"shape_boundary\": mu_upsilon_hat,\n",
    "            \"seg_boundary\": mu_omega_hat[:, 1:2, ...],\n",
    "        }\n",
    "\n",
    "        pred = z if self.training else mu_z\n",
    "        out = {\n",
    "            \"pred_masks\": pred,\n",
    "            \"kl_y\": kl_y,\n",
    "            \"kl_mu_z\": kl_mu_z,\n",
    "            \"kl_sigma_z\": kl_sigma_z,\n",
    "            \"kl_mu_x\": kl_mu_x,\n",
    "            \"kl_sigma_x\": kl_sigma_x,\n",
    "            \"kl_mu_m\": kl_mu_m,\n",
    "            \"kl_sigma_m\": kl_sigma_m,\n",
    "            \"normalization\": normalization,\n",
    "            \"rho\": mu_rho_hat,\n",
    "            \"omega\": mu_omega_hat * digamma_pi,\n",
    "            \"upsilon\": mu_upsilon_hat * mu_z,\n",
    "            # \"visualize\": visualize,\n",
    "        }\n",
    "        return out\n",
    "    \n",
    "class BayeSeg_Criterion(Criterion):\n",
    "    def __init__(self, args):\n",
    "        super(BayeSeg_Criterion, self).__init__(args)\n",
    "        self.bayes_loss_coef = args.bayes_loss_coef\n",
    "\n",
    "    def loss_Bayes(self, outputs):\n",
    "        N = outputs[\"normalization\"]\n",
    "        loss_y = torch.sum(outputs[\"kl_y\"]) / N\n",
    "        loss_mu_m = torch.sum(outputs[\"kl_mu_m\"]) / N\n",
    "        loss_sigma_m = torch.sum(outputs[\"kl_sigma_m\"]) / N\n",
    "        loss_mu_x = torch.sum(outputs[\"kl_mu_x\"]) / N\n",
    "        loss_sigma_x = torch.sum(outputs[\"kl_sigma_x\"]) / N\n",
    "        loss_mu_z = torch.sum(outputs[\"kl_mu_z\"]) / N\n",
    "        loss_sigma_z = torch.sum(outputs[\"kl_sigma_z\"]) / N\n",
    "        loss_Bayes = (\n",
    "            loss_y\n",
    "            + loss_mu_m\n",
    "            + loss_sigma_m\n",
    "            + loss_mu_x\n",
    "            + loss_sigma_x\n",
    "            + loss_mu_z\n",
    "            + loss_sigma_z\n",
    "        )\n",
    "\n",
    "        return loss_Bayes\n",
    "\n",
    "    def forward(self, pred, grnd):\n",
    "        loss_dict = {\n",
    "            \"loss_Dice_CE\": self.compute_dice_ce_loss(pred[\"pred_masks\"], grnd),\n",
    "            \"Dice\": self.compute_dice(pred[\"pred_masks\"], grnd),\n",
    "            \"loss_Bayes\": self.loss_Bayes(pred),\n",
    "            \"rho\": torch.mean(pred[\"rho\"]),\n",
    "            \"omega\": torch.mean(pred[\"omega\"]),\n",
    "            \"upsilon\": torch.mean(pred[\"upsilon\"]),\n",
    "        }\n",
    "        losses = (\n",
    "            loss_dict[\"loss_Dice_CE\"] + self.bayes_loss_coef * loss_dict[\"loss_Bayes\"]\n",
    "        )\n",
    "        return losses, loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1 start!\n",
      "step 2 start!\n",
      "step 3 start!\n",
      "step 4 start!\n",
      "step 5 start!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# (b) Forward pass: generate predictions\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Make a random target for demonstration: shape matches the spatial size of \"output\" \u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# but \"output\" likely has shape [1, num_classes=2, D=32, H=32, W=32].\u001b[39;00m\n\u001b[1;32m     46\u001b[0m target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m160\u001b[39m, \u001b[38;5;241m160\u001b[39m, \u001b[38;5;241m64\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39mdevice)  \u001b[38;5;66;03m# no channel dimension for cross-entropy\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mBayeSeg.forward\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m     81\u001b[0m mu_rho_hat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(mu_rho_hat, \u001b[38;5;241m1e4\u001b[39m, \u001b[38;5;241m1e8\u001b[39m)\n\u001b[1;32m     83\u001b[0m normalization \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(mu_rho_hat)\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m---> 84\u001b[0m n, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_normal_jit(m, torch\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmu_rho_hat\u001b[49m))\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# # Image line upsilon\u001b[39;00m\n\u001b[1;32m     87\u001b[0m alpha_upsilon_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgamma_upsilon \u001b[38;5;241m+\u001b[39m K\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:40\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:970\u001b[0m, in \u001b[0;36mTensor.__rdiv__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;129m@_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__rdiv__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreciprocal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.num_classes = 2\n",
    "        # Hyperparameters referenced in BayeSeg forward pass\n",
    "        self.gamma_rho = 1.0\n",
    "        self.phi_rho = 1.0\n",
    "        self.gamma_upsilon = 1.0\n",
    "        self.phi_upsilon = 1.0\n",
    "        self.gamma_omega = 1.0\n",
    "        self.phi_omega = 1.0\n",
    "        self.alpha_pi = 1.0\n",
    "        self.beta_pi = 1.0\n",
    "        self.sigma_0 = 1.0\n",
    "        # If you have other hyperparameters or parameters, define them here\n",
    "        self.bayes_loss_coef = 1.0 \n",
    "        self.ce_loss_coef = 1.0 \n",
    "        self.dice_loss_coef = 1.0 \n",
    "\n",
    "\n",
    "args = Args()\n",
    "model = BayeSeg(args).to(device)\n",
    "my_loss = BayeSeg_Criterion(args)\n",
    "# Switch to eval mode (or keep training mode)\n",
    "model.eval()\n",
    "\n",
    "# 3) Create a dummy input. Suppose 1 batch, 1 channel, 128x128 image\n",
    "samples = torch.randint(0, 2, (1, 1, 160, 160, 64), dtype=torch.float32, device=device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Dummy samples for demonstration\n",
    "# shape: [batch_size=1, channels=1, depth=32, height=32, width=32]\n",
    "80\n",
    "for i in range(100):\n",
    "    print(f\"step {i} start!\")\n",
    "    # (a) Zero out the gradients from the previous iteration\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # (b) Forward pass: generate predictions\n",
    "    output = model(samples)\n",
    "    \n",
    "    # Make a random target for demonstration: shape matches the spatial size of \"output\" \n",
    "    # but \"output\" likely has shape [1, num_classes=2, D=32, H=32, W=32].\n",
    "    target = torch.randint(0, 2, (1, 1, 160, 160, 64), dtype=torch.float32, device=device)  # no channel dimension for cross-entropy\n",
    "\n",
    "    # (c) Compute the loss\n",
    "    loss = my_loss(output, target)\n",
    "\n",
    "    # (d) Backward pass: compute gradients\n",
    "    loss[0].backward()\n",
    "\n",
    "    # (e) Take an optimizer step to update model parameters\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayeSeg(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(BayeSeg, self).__init__()\n",
    "\n",
    "        self.args = args\n",
    "        self.num_classes = args.num_classes\n",
    "\n",
    "        self.res_shape = ResNet_shape(num_out_ch=2)\n",
    "        self.res_appear = ResNet_appearance(num_out_ch=2, num_block=6, bn=True)\n",
    "        self.unet = get_efficientunet_b2(      \n",
    "            out_channels=2 * args.num_classes, pretrained=False\n",
    "        )\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        Dx = torch.zeros([1, 1, 3, 3], dtype=torch.float)\n",
    "        Dx[:, :, 1, 1] = 1\n",
    "        Dx[:, :, 1, 0] = Dx[:, :, 1, 2] = Dx[:, :, 0, 1] = Dx[:, :, 2, 1] = -1 / 4\n",
    "        self.Dx = nn.Parameter(data=Dx, requires_grad=False)\n",
    "\n",
    "    @staticmethod\n",
    "    def sample_normal_jit(mu, log_var):\n",
    "        sigma = torch.exp(log_var / 2)\n",
    "        eps = mu.mul(0).normal_()\n",
    "        z = eps.mul_(sigma).add_(mu)\n",
    "        return z, eps\n",
    "\n",
    "    def generate_m(self, samples):\n",
    "        feature = self.res_appear(samples)\n",
    "        mu_m, log_var_m = torch.chunk(feature, 2, dim=1)\n",
    "        log_var_m = torch.clamp(log_var_m, -20, 0)\n",
    "        m, _ = self.sample_normal_jit(mu_m, log_var_m)\n",
    "        return m, mu_m, log_var_m\n",
    "\n",
    "    def generate_x(self, samples):\n",
    "        feature = self.res_shape(samples)\n",
    "        mu_x, log_var_x = torch.chunk(feature, 2, dim=1)\n",
    "        log_var_x = torch.clamp(log_var_x, -20, 0)\n",
    "        x, _ = self.sample_normal_jit(mu_x, log_var_x)\n",
    "        return x, mu_x, log_var_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch.nn import init as init\n",
    "from torch.nn.modules.batchnorm import _BatchNorm\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def default_init_weights(module_list, scale=1.0, bias_fill=0.0, **kwargs):\n",
    "    \"\"\"Initialize network weights.\n",
    "\n",
    "    Args:\n",
    "        module_list (list[nn.Module] | nn.Module): Modules to be initialized.\n",
    "        scale (float): Scale initialized weights, especially for residual\n",
    "            blocks. Default: 1.\n",
    "        bias_fill (float): The value to fill bias. Default: 0\n",
    "        kwargs (dict): Other arguments for initialization function.\n",
    "    \"\"\"\n",
    "    if not isinstance(module_list, list):\n",
    "        module_list = [module_list]\n",
    "    for module in module_list:\n",
    "        for m in module.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, **kwargs)\n",
    "                m.weight.data *= scale\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(bias_fill)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.kaiming_normal_(m.weight, **kwargs)\n",
    "                m.weight.data *= scale\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(bias_fill)\n",
    "            elif isinstance(m, _BatchNorm):\n",
    "                init.constant_(m.weight, 1)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(bias_fill)\n",
    "\n",
    "\n",
    "def make_layer(basic_block, num_basic_block, **kwarg):\n",
    "    \"\"\"Make layers by stacking the same blocks.\n",
    "\n",
    "    Args:\n",
    "        basic_block (nn.module): nn.module class for basic block.\n",
    "        num_basic_block (int): number of blocks.\n",
    "\n",
    "    Returns:\n",
    "        nn.Sequential: Stacked blocks in nn.Sequential.\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "    for _ in range(num_basic_block):\n",
    "        layers.append(basic_block(**kwarg))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def default_conv(in_channels, out_channels, kernel_size, strides=1, bias=True):\n",
    "    return nn.Conv3d(\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        strides,\n",
    "        padding=(kernel_size // 2),\n",
    "        bias=bias,\n",
    "    )\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        conv=default_conv,\n",
    "        n_feats=64,\n",
    "        kernel_size=3,\n",
    "        bias=True,\n",
    "        bn=False,\n",
    "        act=nn.ReLU(True),\n",
    "        res_scale=1,\n",
    "    ):\n",
    "        super(ResBlock, self).__init__()\n",
    "        m = []\n",
    "        for i in range(2):\n",
    "            m.append(conv(n_feats, n_feats, kernel_size, bias=bias))\n",
    "            if bn:\n",
    "                m.append(nn.BatchNorm3d(n_feats))\n",
    "            if i == 0:\n",
    "                m.append(act)\n",
    "\n",
    "        self.body = nn.Sequential(*m)\n",
    "        self.res_scale = res_scale\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.body(x).mul(self.res_scale)\n",
    "        res += x\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "class Upsample(nn.Sequential):\n",
    "    \"\"\"Upsample module.\n",
    "\n",
    "    Args:\n",
    "        scale (int): Scale factor. Supported scales: 2^n and 3.\n",
    "        num_feat (int): Channel number of intermediate features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scale, num_feat):\n",
    "        m = []\n",
    "        if (scale & (scale - 1)) == 0:  # scale = 2^n\n",
    "            for _ in range(int(math.log(scale, 2))):\n",
    "                m.append(nn.Conv3d(num_feat, 4 * num_feat, 3, 1, 1))\n",
    "                m.append(nn.PixelShuffle(2))\n",
    "        elif scale == 3:\n",
    "            m.append(nn.Conv3d(num_feat, 9 * num_feat, 3, 1, 1))\n",
    "            m.append(nn.PixelShuffle(3))\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"scale {scale} is not supported. \" \"Supported scales: 2^n and 3.\"\n",
    "            )\n",
    "        super(Upsample, self).__init__(*m)\n",
    "\n",
    "\n",
    "class ResNet_appearance(nn.Module):\n",
    "    def __init__(self, num_in_ch=1, num_out_ch=1, num_feat=64, num_block=10, bn=False):\n",
    "        super(ResNet_appearance, self).__init__()\n",
    "        self.conv_first = nn.Conv3d(num_in_ch, num_feat, 3, 1, 1)\n",
    "        self.body = make_layer(ResBlock, num_block, n_feats=num_feat, bn=bn)\n",
    "        self.conv_last = nn.Conv3d(num_feat, num_out_ch, 3, 1, 1)\n",
    "\n",
    "        # activation function\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "\n",
    "        # initialization\n",
    "        default_init_weights([self.conv_first, self.conv_last], 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.lrelu(self.conv_first(x))\n",
    "        out = self.body(feat)\n",
    "        out = self.conv_last(self.lrelu(out))\n",
    "        out += x\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet_shape(nn.Module):\n",
    "    def __init__(self, num_in_ch=1, num_out_ch=1, num_feat=64, num_block=10, bn=False):\n",
    "        super(ResNet_shape, self).__init__()\n",
    "        self.conv_first = nn.Conv3d(num_in_ch, num_feat, 3, 1, 1)\n",
    "        self.body = make_layer(ResBlock, num_block, n_feats=num_feat, bn=bn)\n",
    "        self.conv_last = nn.Conv3d(num_feat, num_out_ch, 3, 1, 1)\n",
    "\n",
    "        # activation function\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "\n",
    "        # initialization\n",
    "        default_init_weights([self.conv_first, self.conv_last], 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.lrelu(self.conv_first(x))\n",
    "        out = self.body(feat)\n",
    "        out = self.conv_last(self.lrelu(out))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "model = ResNet_shape(num_out_ch=2)\n",
    "samples = torch.randn(1, 1, 128, 128, 128)\n",
    "\n",
    "# 4) Forward pass\n",
    "with torch.no_grad():\n",
    "    output = model(samples)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully split into:\n",
      "Train: 800 cases\n",
      "Validation: 40 cases\n",
      "Test: 160 cases\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define dataset directory (update this path as needed)\n",
    "dataset_dir = r\"/home/molloi-lab-linux2/Desktop/BayeSeg/dataset/imageCAS3d/aaa\"\n",
    "out_dir = r\"/home/molloi-lab-linux2/Desktop/BayeSeg/dataset/imageCAS3d/crop\"\n",
    "\n",
    "# Define output directories\n",
    "output_dirs = {\n",
    "    \"train\": os.path.join(out_dir, \"train\"),\n",
    "    \"val\": os.path.join(out_dir, \"val\"),\n",
    "    \"test\": os.path.join(out_dir, \"test\")\n",
    "}\n",
    "\n",
    "# # Create output directories if they do not exist\n",
    "# for split in output_dirs.values():\n",
    "#     os.makedirs(split, exist_ok=True)\n",
    "\n",
    "# Step 1: Find all unique cases (without \"_Segmentation\")\n",
    "all_files = os.listdir(dataset_dir)\n",
    "all_cases = set()\n",
    "\n",
    "for file_name in all_files:\n",
    "    if file_name.endswith(\".nii.gz\") and \"_Segmentation\" not in file_name:\n",
    "        case_id = file_name.replace(\".nii.gz\", \"\")  # Extract the unique ID (before _Segmentation)\n",
    "        all_cases.add(case_id)\n",
    "\n",
    "# Convert set to list and shuffle\n",
    "all_cases = list(all_cases)\n",
    "random.shuffle(all_cases)\n",
    "\n",
    "# Step 2: Define split sizes\n",
    "train_size = 800\n",
    "val_size = 40\n",
    "test_size = 160\n",
    "\n",
    "# Ensure we have enough cases\n",
    "assert len(all_cases) >= train_size + val_size + test_size, \"Not enough cases for the requested split!\"\n",
    "\n",
    "# Step 3: Split the dataset\n",
    "train_cases = all_cases[:train_size]\n",
    "val_cases = all_cases[train_size:train_size + val_size]\n",
    "test_cases = all_cases[train_size + val_size:train_size + val_size + test_size]\n",
    "\n",
    "# Function to move paired files (image + segmentation) to the respective split folders\n",
    "def move_case(case_id, destination):\n",
    "    for suffix in [\"\", \"_Segmentation\"]:  # Handle both image and segmentation files\n",
    "        file_name = f\"{case_id}{suffix}.nii.gz\"\n",
    "        src_path = os.path.join(dataset_dir, file_name)\n",
    "        dest_path = os.path.join(destination, file_name)\n",
    "        if os.path.exists(src_path):  # Check if file exists before moving\n",
    "            shutil.move(src_path, dest_path)\n",
    "\n",
    "# Step 4: Move files into train, val, and test folders\n",
    "for case in train_cases:\n",
    "    move_case(case, output_dirs[\"train\"])\n",
    "\n",
    "for case in val_cases:\n",
    "    move_case(case, output_dirs[\"val\"])\n",
    "\n",
    "for case in test_cases:\n",
    "    move_case(case, output_dirs[\"test\"])\n",
    "\n",
    "print(f\"Dataset successfully split into:\\nTrain: {len(train_cases)} cases\\nValidation: {len(val_cases)} cases\\nTest: {len(test_cases)} cases\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
